{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6069e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision \n",
    "from torchvision import datasets,transforms \n",
    "import os \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0a381338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 313)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_gray = 0.1307\n",
    "stddev_gray = 0.3081\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean_gray,),(stddev_gray,))\n",
    "])\n",
    "\n",
    "#Load MNIST data \n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform = data_transform,\n",
    "    download=False\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform = data_transform,\n",
    "    download=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "56dbb73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape is 60000\n",
      "Test data shape is 10000\n"
     ]
    }
   ],
   "source": [
    "print('Train data shape is {}'.format(len(train_dataset)))\n",
    "print('Test data shape is {}'.format(len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae16d94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f7c86cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_load = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "test_load = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e0d71ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearNet(nn.Module):\n",
    "    def __init__(self,dropout=0.5):\n",
    "        super(LinearNet,self).__init__()\n",
    "        self.linear1 = nn.Linear(784,1200,bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear2 = nn.Linear(1200,1200,bias=False)\n",
    "        self.linear3 = nn.Linear(1200,10,bias=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = x.view(x.size(0),-1)\n",
    "        out = self.linear1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.linear3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "18c2b7a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-aa9f0119d97b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model.pth.tar'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbig_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mbig_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_state_dict'"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "big_model = LinearNet().to(device)\n",
    "\n",
    "load_path = './teacher_linear_model/'\n",
    "if torch.cuda.is_available():\n",
    "    checkpoint = torch.load(load_path + 'model.pth.tar')\n",
    "else:\n",
    "    checkpoint = torch.load(load_path + 'model.pth.tar',  map_location=torch.device('cpu'))\n",
    "    \n",
    "big_model.load_state_dict(checkpoint['model_state_dict'],strict=False)\n",
    "big_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8e4716e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(83)]\n",
      "[tensor(83), tensor(85)]\n",
      "[tensor(83), tensor(85), tensor(84)]\n",
      "[tensor(83), tensor(85), tensor(84), tensor(84)]\n",
      "[tensor(83), tensor(85), tensor(84), tensor(84), tensor(83)]\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "num_epochs = 5 \n",
    "batch_size = 32 \n",
    "\n",
    "train_loss = []\n",
    "train_accuracy = [] \n",
    "\n",
    "model = LinearNet()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()        \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    iterations = 0 \n",
    "    iter_loss = 0.0\n",
    "    for i,(images,labels) in enumerate(train_load):\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        iter_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,predict = torch.max(outputs,dim=1)\n",
    "        correct += (predict == labels).sum() \n",
    "        iterations += 1 \n",
    "    train_loss.append(iter_loss / iterations)\n",
    "    train_accuracy.append((100 * correct // len(train_dataset)))\n",
    "    print(train_accuracy)\n",
    "    torch.save(model.state_dict(), 'model.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4147aaf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearNet(\n",
       "  (linear1): Linear(in_features=784, out_features=1200, bias=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear2): Linear(in_features=1200, out_features=1200, bias=False)\n",
       "  (linear3): Linear(in_features=1200, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_path = './teacher_linear_model/'\n",
    "load_path = load_path + 'model.pth.tar'\n",
    "model.load_state_dict(torch.load(load_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eaa8d22c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(90)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    loss = 0.0\n",
    "    correct = 0\n",
    "    iterations = 0\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "    for i,(images,labels) in enumerate(test_load):\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss += loss.item()\n",
    "        _,predict = torch.max(outputs,dim=1)\n",
    "        correct += (predict == labels).sum()\n",
    "        iterations += 1\n",
    "    \n",
    "test_loss.append(loss/iterations)\n",
    "test_accuracy.append(100 * correct //len(test_dataset))\n",
    "\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1b36e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallLinearNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SmallLinearNet,self).__init__()\n",
    "        self.linear1 = nn.Linear(784,50,bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.linear2 = nn.Linear(50,10,bias=False)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = x.view(x.size(0),-1)\n",
    "        out = self.linear1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9b8b25ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(83), tensor(85), tensor(84), tensor(84), tensor(83), tensor(97), 97]\n"
     ]
    }
   ],
   "source": [
    "small_train_loss = []\n",
    "small_train_accuracy = []\n",
    "\n",
    "model2 = SmallLinearNet()\n",
    "optimizer = torch.optim.Adam(model2.parameters(),lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    iterrations = 0\n",
    "    iter_loss = 0\n",
    "    for i,(images,labels) in enumerate(train_load):\n",
    "        outputs = model2(images)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        iter_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,predict = torch.max(outputs,dim=1)\n",
    "        correct += (predict == labels).sum().item()\n",
    "        iterations += 1 \n",
    "        \n",
    "train_loss.append(iter_loss / iterations)\n",
    "train_accuracy.append((100 * correct // len(train_dataset)))\n",
    "print(train_accuracy)\n",
    "torch.save(model.state_dict(), 'model.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "50b2cc5f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(90),\n",
       " tensor(3089),\n",
       " tensor(3089),\n",
       " tensor(96),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(0),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(1),\n",
       " tensor(2),\n",
       " tensor(2),\n",
       " tensor(2),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(3),\n",
       " tensor(4),\n",
       " tensor(4),\n",
       " tensor(4),\n",
       " tensor(4),\n",
       " tensor(5),\n",
       " tensor(5),\n",
       " tensor(5),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(6),\n",
       " tensor(7),\n",
       " tensor(7),\n",
       " tensor(7),\n",
       " tensor(8),\n",
       " tensor(8),\n",
       " tensor(8),\n",
       " tensor(8),\n",
       " tensor(9),\n",
       " tensor(9),\n",
       " tensor(9),\n",
       " tensor(10),\n",
       " tensor(10),\n",
       " tensor(10),\n",
       " tensor(11),\n",
       " tensor(11),\n",
       " tensor(11),\n",
       " tensor(11),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(12),\n",
       " tensor(13),\n",
       " tensor(13),\n",
       " tensor(13),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(14),\n",
       " tensor(15),\n",
       " tensor(15),\n",
       " tensor(15),\n",
       " tensor(16),\n",
       " tensor(16),\n",
       " tensor(16),\n",
       " tensor(17),\n",
       " tensor(17),\n",
       " tensor(17),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(18),\n",
       " tensor(19),\n",
       " tensor(19),\n",
       " tensor(19),\n",
       " tensor(20),\n",
       " tensor(20),\n",
       " tensor(20),\n",
       " tensor(21),\n",
       " tensor(21),\n",
       " tensor(21),\n",
       " tensor(21),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(22),\n",
       " tensor(23),\n",
       " tensor(23),\n",
       " tensor(23),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(24),\n",
       " tensor(25),\n",
       " tensor(25),\n",
       " tensor(25),\n",
       " tensor(25),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(26),\n",
       " tensor(27),\n",
       " tensor(27),\n",
       " tensor(27),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(28),\n",
       " tensor(29),\n",
       " tensor(29),\n",
       " tensor(29),\n",
       " tensor(30),\n",
       " tensor(30),\n",
       " tensor(30),\n",
       " tensor(31),\n",
       " tensor(31),\n",
       " tensor(31),\n",
       " tensor(32),\n",
       " tensor(32),\n",
       " tensor(32),\n",
       " tensor(33),\n",
       " tensor(33),\n",
       " tensor(33),\n",
       " tensor(33),\n",
       " tensor(34),\n",
       " tensor(34),\n",
       " tensor(34),\n",
       " tensor(35),\n",
       " tensor(35),\n",
       " tensor(35),\n",
       " tensor(36),\n",
       " tensor(36),\n",
       " tensor(36),\n",
       " tensor(37),\n",
       " tensor(37),\n",
       " tensor(37),\n",
       " tensor(37),\n",
       " tensor(38),\n",
       " tensor(38),\n",
       " tensor(38),\n",
       " tensor(39),\n",
       " tensor(39),\n",
       " tensor(39),\n",
       " tensor(40),\n",
       " tensor(40),\n",
       " tensor(40),\n",
       " tensor(40),\n",
       " tensor(41),\n",
       " tensor(41),\n",
       " tensor(41),\n",
       " tensor(42),\n",
       " tensor(42),\n",
       " tensor(42),\n",
       " tensor(43),\n",
       " tensor(43),\n",
       " tensor(43),\n",
       " tensor(44),\n",
       " tensor(44),\n",
       " tensor(44),\n",
       " tensor(44),\n",
       " tensor(45),\n",
       " tensor(45),\n",
       " tensor(45),\n",
       " tensor(46),\n",
       " tensor(46),\n",
       " tensor(46),\n",
       " tensor(47),\n",
       " tensor(47),\n",
       " tensor(47),\n",
       " tensor(47),\n",
       " tensor(48),\n",
       " tensor(48),\n",
       " tensor(48),\n",
       " tensor(49),\n",
       " tensor(49),\n",
       " tensor(49),\n",
       " tensor(50),\n",
       " tensor(50),\n",
       " tensor(50),\n",
       " tensor(51),\n",
       " tensor(51),\n",
       " tensor(51),\n",
       " tensor(52),\n",
       " tensor(52),\n",
       " tensor(52),\n",
       " tensor(53),\n",
       " tensor(53),\n",
       " tensor(53),\n",
       " tensor(53),\n",
       " tensor(54),\n",
       " tensor(54),\n",
       " tensor(54),\n",
       " tensor(55),\n",
       " tensor(55),\n",
       " tensor(55),\n",
       " tensor(56),\n",
       " tensor(56),\n",
       " tensor(56),\n",
       " tensor(57),\n",
       " tensor(57),\n",
       " tensor(57),\n",
       " tensor(57),\n",
       " tensor(58),\n",
       " tensor(58),\n",
       " tensor(58),\n",
       " tensor(59),\n",
       " tensor(59),\n",
       " tensor(59),\n",
       " tensor(60),\n",
       " tensor(60),\n",
       " tensor(60),\n",
       " tensor(61),\n",
       " tensor(61),\n",
       " tensor(61),\n",
       " tensor(62),\n",
       " tensor(62),\n",
       " tensor(62),\n",
       " tensor(63),\n",
       " tensor(63),\n",
       " tensor(63),\n",
       " tensor(63),\n",
       " tensor(64),\n",
       " tensor(64),\n",
       " tensor(64),\n",
       " tensor(65),\n",
       " tensor(65),\n",
       " tensor(65),\n",
       " tensor(66),\n",
       " tensor(66),\n",
       " tensor(66),\n",
       " tensor(67),\n",
       " tensor(67),\n",
       " tensor(67),\n",
       " tensor(68),\n",
       " tensor(68),\n",
       " tensor(68),\n",
       " tensor(68),\n",
       " tensor(69),\n",
       " tensor(69),\n",
       " tensor(69),\n",
       " tensor(70),\n",
       " tensor(70),\n",
       " tensor(70),\n",
       " tensor(71),\n",
       " tensor(71),\n",
       " tensor(71),\n",
       " tensor(72),\n",
       " tensor(72),\n",
       " tensor(72),\n",
       " tensor(73),\n",
       " tensor(73),\n",
       " tensor(73),\n",
       " tensor(74),\n",
       " tensor(74),\n",
       " tensor(74),\n",
       " tensor(74),\n",
       " tensor(75),\n",
       " tensor(75),\n",
       " tensor(75),\n",
       " tensor(76),\n",
       " tensor(76),\n",
       " tensor(76),\n",
       " tensor(77),\n",
       " tensor(77),\n",
       " tensor(77),\n",
       " tensor(78),\n",
       " tensor(78),\n",
       " tensor(78),\n",
       " tensor(79),\n",
       " tensor(79),\n",
       " tensor(79),\n",
       " tensor(79),\n",
       " tensor(80),\n",
       " tensor(80),\n",
       " tensor(80),\n",
       " tensor(81),\n",
       " tensor(81),\n",
       " tensor(81),\n",
       " tensor(82),\n",
       " tensor(82),\n",
       " tensor(82),\n",
       " tensor(83),\n",
       " tensor(83),\n",
       " tensor(83),\n",
       " tensor(84),\n",
       " tensor(84),\n",
       " tensor(84),\n",
       " tensor(84),\n",
       " tensor(85),\n",
       " tensor(85),\n",
       " tensor(85),\n",
       " tensor(86),\n",
       " tensor(86),\n",
       " tensor(86),\n",
       " tensor(87),\n",
       " tensor(87),\n",
       " tensor(87),\n",
       " tensor(88),\n",
       " tensor(88),\n",
       " tensor(88),\n",
       " tensor(89),\n",
       " tensor(89),\n",
       " tensor(89),\n",
       " tensor(90),\n",
       " tensor(90),\n",
       " tensor(90),\n",
       " tensor(91),\n",
       " tensor(91),\n",
       " tensor(91),\n",
       " tensor(91),\n",
       " tensor(92),\n",
       " tensor(92),\n",
       " tensor(92),\n",
       " tensor(93),\n",
       " tensor(93),\n",
       " tensor(93),\n",
       " tensor(94),\n",
       " tensor(94),\n",
       " tensor(94),\n",
       " tensor(95),\n",
       " tensor(95),\n",
       " tensor(95),\n",
       " tensor(95),\n",
       " tensor(96),\n",
       " tensor(96),\n",
       " tensor(96),\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 11,\n",
       " 11,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 12,\n",
       " 13,\n",
       " 13,\n",
       " 13,\n",
       " 14,\n",
       " 14,\n",
       " 14,\n",
       " 15,\n",
       " 15,\n",
       " 15,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 18,\n",
       " 18,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 19,\n",
       " 20,\n",
       " 20,\n",
       " 20,\n",
       " 21,\n",
       " 21,\n",
       " 21,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 22,\n",
       " 23,\n",
       " 23,\n",
       " 23,\n",
       " 24,\n",
       " 24,\n",
       " 24,\n",
       " 25,\n",
       " 25,\n",
       " 25,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 26,\n",
       " 27,\n",
       " 27,\n",
       " 27,\n",
       " 28,\n",
       " 28,\n",
       " 28,\n",
       " 29,\n",
       " 29,\n",
       " 29,\n",
       " 30,\n",
       " 30,\n",
       " 30,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 31,\n",
       " 32,\n",
       " 32,\n",
       " 32,\n",
       " 33,\n",
       " 33,\n",
       " 33,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 35,\n",
       " 35,\n",
       " 35,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 36,\n",
       " 37,\n",
       " 37,\n",
       " 37,\n",
       " 38,\n",
       " 38,\n",
       " 38,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 39,\n",
       " 40,\n",
       " 40,\n",
       " 40,\n",
       " 41,\n",
       " 41,\n",
       " 41,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 42,\n",
       " 43,\n",
       " 43,\n",
       " 43,\n",
       " 44,\n",
       " 44,\n",
       " 44,\n",
       " 45,\n",
       " 45,\n",
       " 45,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 46,\n",
       " 47,\n",
       " 47,\n",
       " 47,\n",
       " 48,\n",
       " 48,\n",
       " 48,\n",
       " 49,\n",
       " 49,\n",
       " 49,\n",
       " 50,\n",
       " 50,\n",
       " 50,\n",
       " 51,\n",
       " 51,\n",
       " 51,\n",
       " 52,\n",
       " 52,\n",
       " 52,\n",
       " 53,\n",
       " 53,\n",
       " 53,\n",
       " 53,\n",
       " 54,\n",
       " 54,\n",
       " 54,\n",
       " 55,\n",
       " 55,\n",
       " 55,\n",
       " 56,\n",
       " 56,\n",
       " 56,\n",
       " 57,\n",
       " 57,\n",
       " 57,\n",
       " 57,\n",
       " 58,\n",
       " 58,\n",
       " 58,\n",
       " 59,\n",
       " 59,\n",
       " 59,\n",
       " 60,\n",
       " 60,\n",
       " 60,\n",
       " 61,\n",
       " 61,\n",
       " 61,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 62,\n",
       " 63,\n",
       " 63,\n",
       " 63,\n",
       " 64,\n",
       " 64,\n",
       " 64,\n",
       " 65,\n",
       " 65,\n",
       " 65,\n",
       " 66,\n",
       " 66,\n",
       " 66,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 67,\n",
       " 68,\n",
       " 68,\n",
       " 68,\n",
       " 69,\n",
       " 69,\n",
       " 69,\n",
       " 70,\n",
       " 70,\n",
       " 70,\n",
       " 71,\n",
       " 71,\n",
       " 71,\n",
       " 72,\n",
       " 72,\n",
       " 72,\n",
       " 73,\n",
       " 73,\n",
       " 73,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 75,\n",
       " 75,\n",
       " 75,\n",
       " 76,\n",
       " 76,\n",
       " 76,\n",
       " 77,\n",
       " 77,\n",
       " 77,\n",
       " 78,\n",
       " 78,\n",
       " 78,\n",
       " 79,\n",
       " 79,\n",
       " 79,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 80,\n",
       " 81,\n",
       " 81,\n",
       " 81,\n",
       " 82,\n",
       " 82,\n",
       " 82,\n",
       " 83,\n",
       " 83,\n",
       " 83,\n",
       " 84,\n",
       " 84,\n",
       " 84,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 85,\n",
       " 86,\n",
       " 86,\n",
       " 86,\n",
       " 87,\n",
       " 87,\n",
       " 87,\n",
       " 88,\n",
       " 88,\n",
       " 88,\n",
       " 89,\n",
       " 89,\n",
       " 89,\n",
       " 90,\n",
       " 90,\n",
       " 90,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 91,\n",
       " 92,\n",
       " 92,\n",
       " 92,\n",
       " 93,\n",
       " 93,\n",
       " 93,\n",
       " 94,\n",
       " 94,\n",
       " 94,\n",
       " 95,\n",
       " 95,\n",
       " 95,\n",
       " 96,\n",
       " 96,\n",
       " 96,\n",
       " 96,\n",
       " 97,\n",
       " 0.31,\n",
       " 0.63,\n",
       " 0.95,\n",
       " 1.27,\n",
       " 1.59,\n",
       " 1.91,\n",
       " 2.23,\n",
       " 2.54,\n",
       " 2.86,\n",
       " 3.18,\n",
       " 3.48,\n",
       " 3.79,\n",
       " 4.1,\n",
       " 4.41,\n",
       " 4.73,\n",
       " 5.04,\n",
       " 5.36,\n",
       " 5.68,\n",
       " 5.98,\n",
       " 6.27,\n",
       " 6.59,\n",
       " 6.89,\n",
       " 7.2,\n",
       " 7.51,\n",
       " 7.83,\n",
       " 8.13,\n",
       " 8.43,\n",
       " 8.75,\n",
       " 9.07,\n",
       " 9.35,\n",
       " 9.67,\n",
       " 9.98,\n",
       " 10.28,\n",
       " 10.6,\n",
       " 10.91,\n",
       " 11.22,\n",
       " 11.51,\n",
       " 11.83,\n",
       " 12.09,\n",
       " 12.38,\n",
       " 12.69,\n",
       " 12.98,\n",
       " 13.29,\n",
       " 13.59,\n",
       " 13.9,\n",
       " 14.2,\n",
       " 14.49,\n",
       " 14.78,\n",
       " 15.08,\n",
       " 15.39,\n",
       " 15.69,\n",
       " 16.01,\n",
       " 16.32,\n",
       " 16.62,\n",
       " 16.92,\n",
       " 17.23,\n",
       " 17.54,\n",
       " 17.85,\n",
       " 18.16,\n",
       " 18.47,\n",
       " 18.76,\n",
       " 19.06,\n",
       " 19.35,\n",
       " 19.63,\n",
       " 19.91,\n",
       " 20.2,\n",
       " 20.5,\n",
       " 20.81,\n",
       " 21.12,\n",
       " 21.44,\n",
       " 21.76,\n",
       " 22.05,\n",
       " 22.37,\n",
       " 22.69,\n",
       " 22.98,\n",
       " 23.27,\n",
       " 23.59,\n",
       " 23.89,\n",
       " 24.2,\n",
       " 24.52,\n",
       " 24.82,\n",
       " 25.11,\n",
       " 25.4,\n",
       " 25.72,\n",
       " 26.02,\n",
       " 26.32,\n",
       " 26.63,\n",
       " 26.94,\n",
       " 27.26,\n",
       " 27.57,\n",
       " 27.88,\n",
       " 28.18,\n",
       " 28.49,\n",
       " 28.8,\n",
       " 29.12,\n",
       " 29.44,\n",
       " 29.75,\n",
       " 30.06,\n",
       " 30.37,\n",
       " 30.68,\n",
       " 31.0,\n",
       " 31.32,\n",
       " 31.64,\n",
       " 31.96,\n",
       " 32.28,\n",
       " 32.59,\n",
       " 32.9,\n",
       " 33.21,\n",
       " 33.53,\n",
       " 33.84,\n",
       " 34.15,\n",
       " 34.44,\n",
       " 34.75,\n",
       " 35.07,\n",
       " 35.38,\n",
       " 35.69,\n",
       " 36.0,\n",
       " 36.29,\n",
       " 36.58,\n",
       " 36.88,\n",
       " 37.18,\n",
       " 37.49,\n",
       " 37.8,\n",
       " 38.09,\n",
       " 38.39,\n",
       " 38.69,\n",
       " 39.01,\n",
       " 39.29,\n",
       " 39.61,\n",
       " 39.92,\n",
       " 40.21,\n",
       " 40.51,\n",
       " 40.81,\n",
       " 41.12,\n",
       " 41.4,\n",
       " 41.71,\n",
       " 42.02,\n",
       " 42.34,\n",
       " 42.65,\n",
       " 42.97,\n",
       " 43.28,\n",
       " 43.59,\n",
       " 43.89,\n",
       " 44.2,\n",
       " 44.5,\n",
       " 44.82,\n",
       " 45.14,\n",
       " 45.46,\n",
       " 45.76,\n",
       " 46.08,\n",
       " 46.38,\n",
       " 46.69,\n",
       " 46.98,\n",
       " 47.29,\n",
       " 47.61,\n",
       " 47.92,\n",
       " 48.24,\n",
       " 48.56,\n",
       " 48.88,\n",
       " 49.2,\n",
       " 49.52,\n",
       " 49.84,\n",
       " 50.16,\n",
       " 50.47,\n",
       " 50.79,\n",
       " 51.11,\n",
       " 51.42,\n",
       " 51.74,\n",
       " 52.06,\n",
       " 52.38,\n",
       " 52.69,\n",
       " 53.01,\n",
       " 53.33,\n",
       " 53.65,\n",
       " 53.97,\n",
       " 54.27,\n",
       " 54.58,\n",
       " 54.9,\n",
       " 55.22,\n",
       " 55.51,\n",
       " 55.82,\n",
       " 56.14,\n",
       " 56.45,\n",
       " 56.76,\n",
       " 57.08,\n",
       " 57.38,\n",
       " 57.65,\n",
       " 57.94,\n",
       " 58.24,\n",
       " 58.53,\n",
       " 58.85,\n",
       " 59.17,\n",
       " 59.46,\n",
       " 59.78,\n",
       " 60.1,\n",
       " 60.42,\n",
       " 60.74,\n",
       " 61.06,\n",
       " 61.38,\n",
       " 61.7,\n",
       " 62.02,\n",
       " 62.34,\n",
       " 62.66,\n",
       " 62.98,\n",
       " 63.29,\n",
       " 63.58,\n",
       " 63.86,\n",
       " 64.17,\n",
       " 64.49,\n",
       " 64.81,\n",
       " 65.12,\n",
       " 65.41,\n",
       " 65.72,\n",
       " 66.04,\n",
       " 66.36,\n",
       " 66.68,\n",
       " 67.0,\n",
       " 67.32,\n",
       " 67.64,\n",
       " 67.96,\n",
       " 68.28,\n",
       " 68.59,\n",
       " 68.91,\n",
       " 69.23,\n",
       " 69.55,\n",
       " 69.86,\n",
       " 70.18,\n",
       " 70.5,\n",
       " 70.82,\n",
       " 71.13,\n",
       " 71.45,\n",
       " 71.77,\n",
       " 72.08,\n",
       " 72.4,\n",
       " 72.72,\n",
       " 73.04,\n",
       " 73.36,\n",
       " 73.68,\n",
       " 74.0,\n",
       " 74.32,\n",
       " 74.64,\n",
       " 74.96,\n",
       " 75.28,\n",
       " 75.6,\n",
       " 75.92,\n",
       " 76.23,\n",
       " 76.54,\n",
       " 76.85,\n",
       " 77.17,\n",
       " 77.49,\n",
       " 77.81,\n",
       " 78.12,\n",
       " 78.42,\n",
       " 78.74,\n",
       " 79.06,\n",
       " 79.38,\n",
       " 79.7,\n",
       " 80.01,\n",
       " 80.3,\n",
       " 80.6,\n",
       " 80.9,\n",
       " 81.22,\n",
       " 81.51,\n",
       " 81.83,\n",
       " 82.14,\n",
       " 82.46,\n",
       " 82.76,\n",
       " 83.08,\n",
       " 83.4,\n",
       " 83.72,\n",
       " 84.04,\n",
       " 84.36,\n",
       " 84.68,\n",
       " 85.0,\n",
       " 85.32,\n",
       " 85.64,\n",
       " 85.96,\n",
       " 86.28,\n",
       " 86.6,\n",
       " 86.92,\n",
       " 87.24,\n",
       " 87.53,\n",
       " 87.84,\n",
       " 88.15,\n",
       " 88.47,\n",
       " 88.79,\n",
       " 89.11,\n",
       " 89.43,\n",
       " 89.75,\n",
       " 90.07,\n",
       " 90.39,\n",
       " 90.71,\n",
       " 91.03,\n",
       " 91.35,\n",
       " 91.66,\n",
       " 91.98,\n",
       " 92.3,\n",
       " 92.62,\n",
       " 92.94,\n",
       " 93.25,\n",
       " 93.56,\n",
       " 93.87,\n",
       " 94.18,\n",
       " 94.49,\n",
       " 94.78,\n",
       " 95.07,\n",
       " 95.37,\n",
       " 95.68,\n",
       " 96.0,\n",
       " 96.31,\n",
       " 96.62,\n",
       " 96.93,\n",
       " 97.09]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct  =0\n",
    "    iterations = 0\n",
    "    iter_loss = 0\n",
    "    \n",
    "    test_loss = []\n",
    "    test_acuracy = []\n",
    "    \n",
    "    for i, (images,labels) in enumerate(test_load):\n",
    "        outputs = model2(images)\n",
    "        loss = loss_fn(outputs,labels)\n",
    "        loss += loss.item()\n",
    "        _,predict = torch.max(outputs,dim=1)\n",
    "        correct += (predict == labels).sum().item()\n",
    "        iterations += 1\n",
    "        \n",
    "        test_loss.append(loss/iterations)\n",
    "        test_accuracy.append(100 * correct / len(test_dataset))\n",
    "    \n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7870ed30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearNet(\n",
       "  (linear1): Linear(in_features=784, out_features=1200, bias=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear2): Linear(in_features=1200, out_features=1200, bias=False)\n",
       "  (linear3): Linear(in_features=1200, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_path = './small_linear_model/'\n",
    "load_path = load_path + 'model.pth.tar'\n",
    "\n",
    "model.load_state_dict(torch.load(load_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0d5ec8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(scores,targets,T=5):\n",
    "    soft_pred = nn.Softmax(scores / 5)\n",
    "    soft_targets = nn.Softmax(targets / 5)\n",
    "    loss = nn.MSELoss(soft_pred,soft_targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8486651f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'MSELoss' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-26c44da9f4b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 772\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'MSELoss' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "#Distrill\n",
    "model3 = SmallLinearNet()\n",
    "optimizer = torch.optim.Adam(model3.parameters(),lr=5e-3)\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "epochs = 5\n",
    "temp = 5 \n",
    "iterations = 0\n",
    "correct = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i ,(images,labels) in enumerate(train_load):\n",
    "        scores = model2(images)\n",
    "        targets = model(images)\n",
    "        loss = my_loss(scores,targets,T=temp)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        correct += (scores == labels).sum()\n",
    "        iterations += 1\n",
    "\n",
    "train_accuracy.append(100 * correct / len(train_load))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac9c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
